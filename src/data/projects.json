[
  {
    "title": "Gentle Heart Company (GHC) Nepal",
    "desc": "Helping a non-profit in Nepal to setup their WordPress site with e-commerce and e-booking.",
    "link": "https://ghcnepal.com",
    "project_link": "",
    "status": "Ongoing"
  },
  {
    "title": "Connection CLI",
    "desc": "This is an upgrade to the connection script that was written few years ago. The idea is to mimic AWS and Azure CLI and can do more than just connection. This is accomplished using Python and Click package.",
    "link": "",
    "project_link": "",
    "status": "Ongoing"
  },
  {
    "title": "Use CDK to Create Environment",
    "desc": "Due to the limitation of CloudFormation, I had to use CDK to streamline the process of deploying an environment from scratch.",
    "link": "",
    "project_link": "",
    "status": "Ongoing"
  },
  {
    "title": "Use Bicep to Create Environment in Azure",
    "desc": "For some customers, there's a need to create an environment in Azure, so I started working on it using Bicep.",
    "link": "",
    "project_link": "",
    "status": "Ongoing"
  },
  {
    "title": "Automate Ticket Creation",
    "desc": "A recent request is to automatically create a ticket based on a certain event such as vulnerability, system impaired, etc.",
    "link": "",
    "project_link": "",
    "status": "Ongoing"
  },
  {
    "title": "Build Multiple Cloud-based Environment for SaaS platform",
    "desc": "I help build dev, qa, staging, and production environment. Each in different AWS account and peered with a hub VPC, so we can use a single VPN to access resources in all of them. For more information, please visit the project link.",
    "link": "",
    "project_link": "https://github.com/nik-yo/SaasPlatform",
    "status": "Completed"
  },
  {
    "title": "Build CI/CD Pipelines in Azure DevOps",
    "desc": "There are multiple different pipelines such as .NET, Nuget, Python, Node.js, EF schema migration.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Host WordPress in AWS",
    "desc": "One of the requests from a marketing department is to host a WordPress site in AWS.",
    "link": "",
    "project_link": "https://github.com/nik-yo/NikYo.Aws.WordPress",
    "status": "Completed"
  },
  {
    "title": "Internal Reporting Process",
    "desc": "I need to setup a temporary process for internal reporting tools due to sunsetting a legacy platform.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Data Obfuscation Process",
    "desc": "An operation team requested data to be copied and obfuscated for their demo purposes, so I setup a process to do that automatically.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Handled Notification from AWS Marketplace",
    "desc": "One of the requests was to handle marketplace notification from AWS Marketplace. I build the infrastructure to handle this and it involves cross-account cross-region connections.",
    "link": "",
    "project_link": "https://github.com/nik-yo/NikYo.Aws.CrossRegionNoCodeMessaging",
    "status": "Completed"
  },
  {
    "title": "Dynamic Workers Deployments per Kafka Topic",
    "desc": "I had to configure CI/CD pipelines that takes one application and split it into multiple deployments where each deployment will handle one Kafka topic for Kubernetes. This is so we can scale per topic. And the process has to handle if a new topic is introduced and old topic is removed without any manual configuration change.",
    "link": "",
    "project_link": "https://github.com/nik-yo/WorkersPerTopic",
    "status": "Completed"
  },
  {
    "title": "Web Page to Allow Customer to Configure Single Sign-On (SSO)",
    "desc": "Until we have the page, customer has to contact me to configure their SSO to the application, so I wrote a page in React with .NET web api backend to allow them to configure it that themselves along with the documentation.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Get Application Published in Okta Catalog",
    "desc": "For customers that use Okta, Okta catalog is a very convenient way to setup SSO, so I was asked to get our application published in there. It took a bit back and forth with the representative, but I managed to get the app published.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Mobile Application Development",
    "desc": "There was an iOS mobile app project that has been ongoing for 9 months. I took over the project and spend 3 months to clean up and publish the iOS application and another 3 months to publish the android application.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Get Memory Dump from .NET Application and Upload to S3",
    "desc": "I helped wrote a script and inject it into the .NET container to simplify getting memory dump and upload it to S3. There are two processes, one is to get whole memory dump, another one is to get GC dump.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Automatically Run CSX Script and Perform Version Control Process",
    "desc": "The request is to free a developer from manual work where he needs to run a csx script quarterly, create a branch, commit and push the change, and create a pull request. I did that automatically in Azure DevOps.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Downsize EBS Programmatically",
    "desc": "I had to design a process and wrote a script to move data from an EBS to a smaller EBS. This involved create a smaller EBS and a worker EC2, creating partition table, file system, sector copy the data, create a snapshot of old EBS and delete the original.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "S3 Bundling PoC",
    "desc": "To reduce API call into S3, one solution is to archived files together before we push it to S3. As part of the PoC, I had to architect a process to keep track of the files and be able to retrieve only 1 file in the archive if needed.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Implement Scrolling in Silverlight Image Viewer",
    "desc": "A request from sales department in which the image viewer was not intuitive to use. I ended up customize the code so customer can scroll to view image displayed in there.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Streamline Monthly Report Generation",
    "desc": "When I first encounter the process, there are so many manual work that it took at least one week to create 3 reports. I had to write VBA code to run macros and with 2 commands, I managed to create 24 reports in 3 days (with verification).",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Containerize Batch Application",
    "desc": "The batch application was initially run in VMs, but they didn't scale, so I propose a containerization process. The first attempt without code change caused the container to swell to 1GB in size (.NET framework). I had the developer to upgrade it to .NET Core. It's better but due to old dependency, it can only run in Windows container and cost a lot (minimum charge is 15 minutes in ECS), so I had to refactor the code to enable it to run in Linux container. That saved us roughly $7,000 a week.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Git Cleanup Every 90 Days",
    "desc": "Due to the number of old Git branches, I was looking for a way to programmatically do a cleanup by removing any branches that are older than 90 days, so I wrote a script for that.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Upgrade Xen Hypervisor-based EC2 Instance to Nitro-based Instance Programmatically",
    "desc": "I had to write some code and script to make this OS agnostic. The process involved checking the OS, install required drivers, configure fstab (for Linux), check the virtualization. It went to production.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Upgrade from PV virtualization to HVM for EC2 AMI programmatically",
    "desc": "This is part of modernization in AWS that I had to write a code to get an AMI from old PV virtualization to a newer HVM virtualization so it can take advantage of newer architecture in AWS.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Automatically Moved Work Item in Azure DevOps",
    "desc": "Using a combination of ADO service hook and Azure function, I managed to automatically moved work items to the correct column automatically after a PR is completed.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Visual Studio Extension",
    "desc": "I created a Visual Studio extension for developers so they can perform some basic tasks such as changing local machine to point to a certain environment, decrypt encrypted string, perform schema migration on their local database.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Implement Opensearch Snapshot Lifecycle Management",
    "desc": "Before that snapshot lifecycle management was available, I had to create a Lambda with Event Bridge to back up the data using snapshot. That goes away after the feature is available and I reconfigure the snapshot using lifecycle management.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Prevent Accidental Pull Request Merge from Unauthorized Branch",
    "desc": "There are only certain branches that are allowed to merge into specified branch, so in order to prevent accidents, I created a validation script that run when Pull Request is created to check the source and destination branch.",
    "link": "",
    "project_link": "https://github.com/nik-yo/NikYo.AzureDevOps.PRValidation",
    "status": "Completed"
  },
  {
    "title": "OpenVPN Upgrade, Setup and Configured",
    "desc": "In order to access resources in private network, a VPN is required. I had to set this up from scratch and configure it with automatic SSL certificate renewal using certbot.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Site-to-Site VPN",
    "desc": "Customer requires us to get data from their internal network, so I setup site-to-site VPN. I warned the leadership that it will cost us $1,000 a month to maintain this and leadership decided to scrap the idea after it's running for a few weeks.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Workaround Datadog Logging for EKS Fargate",
    "desc": "Datadog suggested that application logs are captured by Fargate logging and then forwarded to their endpoint using Lambda. However, this can be expensive since it requires both Lambda and CloudWatch Logs. Besides, it doesn't work to correlate trace and log. I found a way to use Datadog agent to get the log from shared file system and push it directly to Datadog endpoint for EKS Fargate. This saves us financial and maintenance cost.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Pseudo Blue/Green Deployment for API pods in Kubernetes",
    "desc": "To do a full blue/green deployment for Kubernetes cluster is hard for us, especially when we don't have enough manpower. So, what I did is to create a new deployment everytime there's a new release and after all releases are deployed, I redirect the traffic in Kubernetes service to the new pods.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Database Schema Migration",
    "desc": "I had to implement schema migration by using Azure DevOps to deploy the idempotent SQL script to S3, S3 event notification will trigger lambda. Lambda will pull all the databases that need to be updated and push each one to SQS. SQS in turns triggers (actually Lambda poller checks SQS) another Lambda that actually performs the migration.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Connection Script to Integrate AWS account and Web Application",
    "desc": "I wrote scripts to manage connection betwen AWS account and the web application using PowerShell and Bash scripts.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Update Image using Photoshop",
    "desc": "I was asked to update the year of the image that the company sent to various clients, so we can reuse our image. The challenge is to make it natural enough. I had the experience of removing a person from an image and fix the background, so this was not too bad.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Blur Sensitive Information for a Demo Video",
    "desc": "Our engineer created a demo video, but there are some sensitive information in there, so I used Adobe Premier to blur them out and re-render the video.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Host Rise 360 Exported Educational Content in AWS",
    "desc": "It contains static html and assets and the requirement is only company's employee have access to it. I first hosted it in Static Web App, but the content grew over 250 MB limit, so I moved it to AWS Lightsail with MSAL.js and simple Node.js with serve package.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "White labeling",
    "desc": "Basically the idea is *.example.com has to be routed to our server that will send a copy of the front end unless it is reserved. For example: api.example.com will be routed to the API endpoint, but xyz-company.example.com will be routed to the front end. That way, the app doesn't have to configure every new subdomain for every company that wants white labeling. I accomplished this by configuring Route 53, ALB and Ingress in Kubernetes.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Load Test WordPress Site",
    "desc": "Marketing team WordPress site crashed when they sent out 25,000 marketing emails. So I used Locust to load test the site to allow it to handle minimum of 25,000 concurrent visit.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Automatically Benchmark EC2 Instances",
    "desc": "In order to figure out various performance difference between EC2 instances, I had to automate benchmarking the various EC2 instances using Geekbench on custom EC2 AMI with SSM to automatically run and upload the result to S3.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Aggregate Big Data for Analytics and Web Application Consumption",
    "desc": "In this project, we are talking about hundreds of millions of row with 200+ columns. To do this fast, I wrote Spark application using pySpark on EMR.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Speed Up Big Data Ingestion",
    "desc": "The process to ingest to Elasticsearch was too slow, so I used Apache Phoenix with HBase to speed up data ingestion and serve data to web application. The last performance that I noticed was about 15-20k rows per second ingestion.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  },
  {
    "title": "Create compliance alarms",
    "desc": "The company was pursuing SOC 2 and ISO 27001 certifications and I had to create alarms when certain events occurred so we were notified.",
    "link": "",
    "project_link": "",
    "status": "Completed"
  }
]